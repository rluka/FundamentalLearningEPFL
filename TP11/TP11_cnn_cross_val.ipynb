{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**What did we learn last week?**: We got a first look at PyTorch and trained a deep learning model with automatic differentiation.\n",
    "\n",
    "**What you will learn today**: We will take a closer look at Convolutional Neural Networks and understand why they are ubiquitously used. Then, we will look at the *correct* way of evaluating performance. Finally, we will explore some important hyperparameters/design decision for \n",
    "boosting performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Great sources:\n",
    "- https://poloclub.github.io/cnn-explainer/\n",
    "- https://setosa.io/ev/image-kernels/\n",
    "\n",
    "![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif)\n",
    "\n",
    "**Why convolutions and not fully-connected layers?** In the previous lab, we used a MultiLayer Perceptron (MLP) to perform classification on the MNIST dataset of handwritten digits. However, MLPs expect a vector as an input and, hence, our first step was to *flatten* the image; from an input of shape $(1, 28, 28)$ we got a vector of $1\\times28\\times28=784$ elements. Then, each layer of the MLP is fully connected, meaning that all $784$ elements are fed into each neuron of the next layer.\n",
    "\n",
    "Does this sound reasonable?\n",
    "\n",
    "No! First, by flattening we implicitly lose *local* information. Assume you look at pixel in location $(5,5)$, then the neighboring pixels $(4,5),(6,5), (5,4), (5,6),\\dots$ are important and must be \"somewhat similar\". Second, by using all elements of the previous layer. the top left and bottom right pixels are used in the same computation. \n",
    "\n",
    "Convolutional Neural Networks address these (and more) concerns and are suitable for the image domain. But, what are convolutions? We start with a small matrix of weights, e.g. $3\\times3$, which is called a kernel. The kernel is then slided over the 2d input and we perform elementwise multiplication with the values the kernel is currently on. The summation of the $3\\times3=9$ elements is the output for the pixel. Hence, the kernel performs a \"local\" computation. *Back in the day*, kernels were hand-designed to perform a specific operation. For example, the Sobel operator is used for edge-detection:\n",
    "\n",
    "$$\n",
    "\\mathbf{G}_x=\\left[\\begin{array}{ccc}\n",
    "+1 & 0 & -1 \\\\\n",
    "+2 & 0 & -2 \\\\\n",
    "+1 & 0 & -1\n",
    "\\end{array}\\right] * \\mathbf{A} \\quad \\text { and } \\quad \\mathbf{G}_y=\\left[\\begin{array}{ccc}\n",
    "+1 & +2 & +1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{array}\\right] * \\mathbf{A}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{G}=\\sqrt{\\mathbf{G}_x^2+\\mathbf{G}_y^2}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "\n",
    "![](https://miro.medium.com/max/640/1*m9XHMKQPY6mKYsaykuVAsw.webp)\n",
    "\n",
    "Creating filters for every different scenario requires domain knowledge and is cumbersome. (Convolutional) Neural Networks learn the values of these filters in an \"end-to-end\" manner! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our \"local\" library of functions\n",
    "from training_utils import train_epoch, fit, predict, visualize_images\n",
    "\n",
    "# also import everything else that we need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "BATCH_SIZE = 1024\n",
    "TEST_BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# find out which device is available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# load the train dataset\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# load the test dataset\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# define the train and test dataloaders\n",
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # We use a Sequential, i.e. the inputs passes through each of\n",
    "        # the modules below, one-by-one\n",
    "        self.conv = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=...,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=1,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),    \n",
    "        )\n",
    "              \n",
    "        # fully connected layer, output 10 classes   \n",
    "        self.out = nn.Linear(..., 10)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        .... \n",
    "        x = self.out(x)\n",
    "        return x   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "cnn = CNN().to(DEVICE)\n",
    "\n",
    "# define the optimizer.\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1)\n",
    "\n",
    "# train the CNN\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# predict\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# load the CIFAR10 train dataset\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# load the test dataset\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# define the dataloders\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "visualize_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "cnn = CNN().to(DEVICE)\n",
    "\n",
    "# define the optimizer. \n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# train the CNN\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# predict\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above failed! Why? Make modifications to the model and perform the same training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarCNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define the same model as before. What must be changed to make the model \n",
    "        # \"compatible with CIFAR10\"?\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "        # fully connected layer, output 10 classes   \n",
    "        # YOUR CODE GOES HERE\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.out(x)\n",
    "        return x   \n",
    "\n",
    "cnn_cifar = CifarCNN().to(DEVICE)\n",
    "\n",
    "# define the optimizer.\n",
    "optimizer = torch.optim.SGD(cnn_cifar.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# train the CNN\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# predict\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**: CIfar10 is a more complex dataset than MNIST; the images are larger and RGB, the model is larger and a simple training scheme returns very bad results! How can we change this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set\n",
    "\n",
    "Before looking into tips and tricks for boosting the performance of a model, we need to establish a proper evaluation protocol. This is where the validation set comes in. \n",
    "\n",
    "In the real world, we do not have access to the test set, e.g., customer churning or self-driving cars. But, still, we need to evaluate the performance of our models on *unseen data*. The most common way is to split the training set into training+validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "# Split the training set into training + validation. \n",
    "# How many samples does the training set have?\n",
    "print(f\"The training set has {len(train_dataset)} samples.\")\n",
    "\n",
    "# Split the dataset into ?????-10k samples for training-validation.\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# what is the type of the \"new\" training dataset?\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset=valid_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the fit function to also use a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module, \n",
    "    train_dataloader: DataLoader, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    epochs: int, \n",
    "    device: torch.device,\n",
    "    valid_dataloader: Optional[DataLoader]=None):\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "    return train_losses, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(DEVICE)\n",
    "\n",
    "# define the optimizer.\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1)\n",
    "\n",
    "train_losses, valid_losses, valid_accs = fit(\n",
    "    model=cnn, \n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "predict(model=cnn, test_dataloader=test_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of optimizer and learning rate\n",
    "\n",
    "So far in this lab, we have used the same learning rate and optimizer (vanilla SGD). However, the choice of optimizer and the corresponding hyperparameters play a crucial role in the end performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the exact same experiment as before BUT change the learning rate to $0.001$. How does this change affect performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "plt.plot(train_losses, \"-o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE-bh1Sox_Ve"
   },
   "source": [
    "In this lab we have used (mini-batch) Stochastic Gradient Descent or simply SGD. For simplicity we consider the case for only one sample. The update rule is the following:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{(\\tau+1)} \\gets \\mathbf{w}^{(\\tau)} - \\eta\\nabla \\mathcal{L}\\left(\\mathbf{x}, y;\\mathbf{w}^{(\\tau)}\\right)\n",
    "$$\n",
    "\n",
    "How can we improve our algorithm and encourage faster convergence? Momentum can actually help. The idea is simple: we will use the update made on the previous step and incorporate it to our current update, giving momentum to our algorithm. The actual update rule is the following:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{v}^{(\\tau+1)} &\\gets \\gamma\\mathbf{v}^{(\\tau)} + \\nabla \\mathcal{L}\\left(\\mathbf{x}, y;\\mathbf{w}^{(\\tau)}\\right)\n",
    "\\\\\n",
    "\\mathbf{w}^{(\\tau+1)} &\\gets \\mathbf{w}^{(\\tau)} - \\eta \\mathbf{v}^{(\\tau)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Apart from making convergence faster, momentum has other benefits:\n",
    "* dampens oscillations \n",
    "* helps us navigate ravines around local optima [1]\n",
    "\n",
    "If you are more interested in the various optimizers take a look at reference [1].\n",
    "\n",
    "----\n",
    "[1] Ruder, S., 2016. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(DEVICE)\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "train_losses, valid_losses, valid_accs = fit(\n",
    "    model=cnn, \n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "predict(model=cnn, test_dataloader=test_dataloader, device=DEVICE)\n",
    "\n",
    "plt.plot(train_losses, \"-o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters: Learning rate and batch size\n",
    "\n",
    "While intution can help us select the settings of an experiment, the choice becomes complicated when more and more hyperparameters need to be taken account. Just to name a few, we might want to select learning rate, momentum or optimizer, batch size, number of layers, width of layers etc\n",
    "\n",
    "Hence, we need a systematic way to approach this problem. The most simple way is to perfrom a grid search; define a list of choices for each hyperparameter and search over all combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a grid search over 2 values of learning rate and 2 values of Batch size.\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "LR_GRID = [0.01, 0.1]\n",
    "BS_GRID = [256, 512]\n",
    "\n",
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance on the test set with the best model!\n",
    "predict(model=..., test_dataloader=test_dataloader, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10\n",
    "\n",
    "Modify the models, the epochs, the optimizers, the grid search etc and repeat the process on the more challenging dataset of CIFAR10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03a8ff65f077f05ff345d067c3fc612a41150fb0cbc9d89e43af938917f7b052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
